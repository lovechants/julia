# Selective testing workflow based on file changes

name: Selective Tests



on:

  push:

    branches: [ main, develop ]

  pull_request:

    branches: [ main, develop ]



jobs:

  selective-test:

    name: Run Tests Based on Changes

    runs-on: ubuntu-latest



    steps:

    - uses: actions/checkout@v4

      with:

        fetch-depth: 0



    - name: Set up Python

      uses: actions/setup-python@v4

      with:

        python-version: '3.9'



    - name: Install dependencies

      run: |

        python -m pip install --upgrade pip

        pip install numpy pytest-xdist pytest-benchmark

        pip install --force-reinstall "pytest>=7.1.0"

        pip install llvmlite || echo "LLVM not available"

        pip install onnx || echo "ONNX not available"

        pip install psutil || echo "psutil not available"

        pip install -e .

    

    - name: Run targeted tests based on changes
      working-directory: julia
      run: |
        set -e
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD)
        else
          CHANGED_FILES=$(git diff --name-only HEAD~1..HEAD)
        fi

        echo "Changed files:"
        echo "$CHANGED_FILES"
        echo ""

        # Backend/compiler tests
        if echo "$CHANGED_FILES" | grep -E "(backend|llvm|cuda|metal|clang|triton|compiler)" > /dev/null; then
          echo "Backend changes detected - running compiler tests"
          if grep -r "@pytest.mark.compiler" tests/; then
            python -m pytest tests/ -m compiler -v --tb=short
          else
            echo "No compiler tests found, skipping."
          fi
        fi

        # Autograd/ops tests  
        if echo "$CHANGED_FILES" | grep -E "(ops|autograd|tensor\.py|Function)" > /dev/null; then
          echo "Operations/autograd changes detected - running autograd tests"
          if grep -r "@pytest.mark.autograd" tests/; then
            python -m pytest tests/ -m autograd -v --tb=short
          else
            echo "No autograd tests found, skipping."
          fi
        fi

        # Neural network tests
        if echo "$CHANGED_FILES" | grep -E "(nn/|conv|pool|linear|attention)" > /dev/null; then
          echo "Neural network changes detected - running NN tests"
          if grep -r "@pytest.mark.neural_network" tests/; then
            python -m pytest tests/ -m neural_network -v --tb=short
          else
            echo "No neural_network tests found, skipping."
          fi
        fi

        # Numerical accuracy tests
        if echo "$CHANGED_FILES" | grep -E "(ops/|loss\.py|optim\.py)" > /dev/null; then
          echo "Operations/optimization changes detected - running numerical tests"
          if grep -r "@pytest.mark.numerical" tests/; then
            python -m pytest tests/ -m numerical -v --tb=short
          else
            echo "No numerical tests found, skipping."
          fi
        fi

        # Memory management tests
        if echo "$CHANGED_FILES" | grep -E "(memory\.py)" > /dev/null; then
          echo "Memory changes detected - running memory tests"
          if grep -r "@pytest.mark.memory" tests/; then
            python -m pytest tests/ -m memory -v --tb=short
          else
            echo "No memory tests found, skipping."
          fi
        fi

        # Integration tests for examples
        if echo "$CHANGED_FILES" | grep -E "(examples/)" > /dev/null; then
          echo "Example changes detected - running integration tests"
          if grep -r "@pytest.mark.integration" tests/; then
            python -m pytest tests/ -m integration -v --tb=short
          else
            echo "No integration tests found, skipping."
          fi
        fi

        # IR/serialization tests
        if echo "$CHANGED_FILES" | grep -E "(ir\.py|onnx\.py|utils/.*_registry\.py)" > /dev/null; then
          echo "IR/ONNX changes detected - running serialization tests"
          if grep -r "@pytest.mark.serialization" tests/; then
            python -m pytest tests/ -m serialization -v --tb=short
          else
            echo "No serialization tests found, skipping."
          fi
        fi

        # Profiling tests
        if echo "$CHANGED_FILES" | grep -E "(profiler\.py)" > /dev/null; then
          echo "Profiler changes detected - running profiling tests"
          if grep -r "@pytest.mark.profiling" tests/; then
            python -m pytest tests/ -m profiling -v --tb=short
          else
            echo "No profiling tests found, skipping."
          fi
        fi

        # Data handling tests
        if echo "$CHANGED_FILES" | grep -E "(data\.py|data_utils\.py)" > /dev/null; then
          echo "Data handling changes detected - running data tests"
          if grep -r "@pytest.mark.data" tests/; then
            python -m pytest tests/ -m data -v --tb=short
          else
            echo "No data tests found, skipping."
          fi
        fi

        # Benchmarks for performance-critical changes
        if echo "$CHANGED_FILES" | grep -E "(ops/|autograd|tensor\.py|backend/)" > /dev/null; then
          echo "Performance-critical changes detected - running benchmarks"
          if grep -r "@pytest.mark.benchmark" tests/; then
            python -m pytest tests/ -m benchmark --benchmark-only -v --tb=short
          else
            echo "No benchmark tests found, skipping."
          fi
        fi

        # Slow tests for core framework changes
        if echo "$CHANGED_FILES" | grep -E "(tensor\.py|autograd\.py|ops\.py)" > /dev/null; then
          echo "Core framework changes detected - running slow tests"
          if grep -r "@pytest.mark.slow" tests/; then
            python -m pytest tests/ -m slow -v --tb=short
          else
            echo "No slow tests found, skipping."
          fi
        fi

    

    - name: Upload test results

      uses: actions/upload-artifact@v4

      if: always()

      with:

        name: test-results

        path: |

          pytest-report.xml

          .coverage

        retention-days: 30



  test-matrix:

    name: Test Matrix for Core Changes

    runs-on: ubuntu-latest

    if: contains(github.event.pull_request.title, '[test-matrix]') || github.event_name == 'push'

    strategy:

      matrix:

        python-version: ['3.8', '3.9', '3.10', '3.11']

        test-type: ['autograd', 'numerical', 'neural_network']



    steps:

    - uses: actions/checkout@v4

      with:

        fetch-depth: 0



    - name: Set up Python ${{ matrix.python-version }}

      uses: actions/setup-python@v4

      with:

        python-version: ${{ matrix.python-version }}



    - name: Install dependencies

      run: |

        python -m pip install --upgrade pip

        pip install numpy pytest

        pip install -e .

    

    - name: Run ${{ matrix.test-type }} tests

      run: |

        python -m pytest tests/ -m "${{ matrix.test-type }}" -v --tb=short



  critical-path-tests:

    name: Critical Path Tests

    runs-on: ubuntu-latest



    steps:

    - uses: actions/checkout@v4



    - name: Set up Python

      uses: actions/setup-python@v4

      with:

        python-version: '3.9'



    - name: Install dependencies

      run: |

        python -m pip install --upgrade pip

        pip install numpy pytest

        pip install -e .

    

    # - name: Run critical path tests #Boilerplate to fix at some point soon

    #   run: |

    #     echo "Running critical path tests"

    #

    #     # Core tensor operations

    #     python -m pytest tests/ -k "test_tensor_creation or test_basic_arithmetic or test_autograd_simple" -v

    #

    #     # Basic autograd functionality

    #     python -m pytest tests/ -k "test_backward_simple or test_gradient_flow" -v

    #

    #     # Essential operations

    #     python -m pytest tests/ -k "test_matmul_basic or test_relu_basic or test_sigmoid_basic" -v



  backend-tests:

    name: Backend-Specific Tests

    runs-on: ${{ matrix.os }}

    strategy:

      fail-fast: false

      matrix:

        include:

          - name: "LLVM CPU Backend"

            os: ubuntu-latest

            install: "llvmlite"

            markers: "compiler_cpu_llvm"

          - name: "Clang CPU Backend"

            os: ubuntu-latest

            install: "clang"

            markers: "compiler_cpu_clang"

            setup: |

              sudo apt-get update

              sudo apt-get install -y clang

          - name: "CUDA Backend"

            os: ubuntu-latest

            install: "pycuda"

            markers: "compiler_gpu_cuda"

            setup: |

              wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb

              sudo dpkg -i cuda-keyring_1.0-1_all.deb

              sudo apt-get update

              sudo apt-get -y install cuda-toolkit-11-8

            skip_on_no_gpu: true

          - name: "Triton Backend"

            os: ubuntu-latest

            install: "triton"

            markers: "compiler_gpu_triton"

            setup: |

              wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb

              sudo dpkg -i cuda-keyring_1.0-1_all.deb

              sudo apt-get update

              sudo apt-get -y install cuda-toolkit-11-8

            skip_on_no_gpu: true

          - name: "OpenCL Backend"

            os: ubuntu-latest

            install: "pyopencl"

            markers: "compiler_gpu_opencl"

            setup: |

              sudo apt-get update

              sudo apt-get install -y opencl-headers ocl-icd-opencl-dev

          - name: "ROCm Backend"

            os: ubuntu-latest

            install: "hip-python"

            markers: "compiler_gpu_rocm"

            setup: |

              wget -qO - https://repo.radeon.com/rocm/rocm.gpg.key | sudo apt-key add -

              echo 'deb [arch=amd64] https://repo.radeon.com/rocm/apt/debian/ ubuntu main' | sudo tee /etc/apt/sources.list.d/rocm.list

              sudo apt-get update

              sudo apt-get install -y rocm-dev

            skip_on_no_gpu: true

          - name: "Metal Backend"

            os: macos-latest

            install: "pyobjc-framework-Metal"

            markers: "compiler_gpu_metal"

          - name: "ONNX Support"

            os: ubuntu-latest

            install: "onnx onnxruntime"

            markers: "serialization_onnx"

          - name: "Memory Profiling"

            os: ubuntu-latest

            install: "psutil"

            markers: "memory_profiling"



    steps:

    - uses: actions/checkout@v4



    - name: Set up Python

      uses: actions/setup-python@v4

      with:

        python-version: '3.9'



    - name: Install base dependencies

      run: |

        python -m pip install --upgrade pip

        pip install numpy pytest

        pip install -e .



    - name: System setup for ${{ matrix.name }}

      if: matrix.setup

      run: ${{ matrix.setup }}



    - name: Install backend dependencies

      run: |

        pip install ${{ matrix.install }}

      continue-on-error: ${{ matrix.skip_on_no_gpu == true }}



    - name: Check GPU availability

      if: matrix.skip_on_no_gpu == true

      run: |

        if ! nvidia-smi &> /dev/null; then

          echo "No GPU detected, skipping GPU tests"

          echo "SKIP_GPU_TESTS=true" >> $GITHUB_ENV

        fi

      continue-on-error: true



    - name: Run tests for ${{ matrix.name }} if any exist

      if: env.SKIP_GPU_TESTS != 'true'

      run: |

        marker="${{ matrix.markers }}"

        if grep -r "@pytest.mark.${marker}" tests/; then

          echo "Running tests for marker: $marker"

          python -m pytest tests/ -m "$marker" -v --tb=short

        else

          echo "No tests found for marker: $marker, skipping."

        fi



    - name: Run CPU fallback tests

      if: env.SKIP_GPU_TESTS == 'true' && contains(matrix.markers, 'gpu')

      run: |

        if grep -r "@pytest.mark.compiler_cpu" tests/; then

          echo "Running CPU fallback tests"

          python -m pytest tests/ -m "compiler_cpu" -v --tb=short

        else

          echo "No CPU fallback tests found, skipping."

        fi
